{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf3d0a2a",
   "metadata": {},
   "source": [
    "# Project Part III â€“ Model Selection and Regularization\n",
    "\n",
    "This notebook performs:\n",
    "- Model selection using 5-fold cross-validation\n",
    "- Logistic regression with L1, L2, and Elastic Net regularization\n",
    "- Feature engineering and data preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af13522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e943ace",
   "metadata": {},
   "source": [
    "## Part A: Model Selection\n",
    "\n",
    "### 1. Data Loading and Preprocessing\n",
    "We load the dataset, drop missing or duplicate values, and create new features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "054de5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PART A: MODEL SELECTION\n",
      "============================================================\n",
      "1. Loading and preprocessing data...\n",
      "Dataset shape after preprocessing: (28818, 20)\n",
      "Columns: ['Unnamed: 0', 'Tweet', 'Followers', 'Friends', 'Num_tweets', 'Verified', 'Listed_count', 'Location', 'Age', 'Length', 'Num_users', 'Num_author_replies', 'TOXICITY_x', 'Num_toxic_direct_replies', 'Num_toxic_nested_replies', 'Num_author_toxic_replies', 'Num_toxic_replies', 'Toxic', 'Total_toxic_replies', 'Toxic_conversation']\n",
      "Toxic conversation distribution:\n",
      "Toxic_conversation\n",
      "0    21613\n",
      "1     7205\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_data():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PART A: MODEL SELECTION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"1. Loading and preprocessing data...\")\n",
    "    df = pd.read_csv('down_data.csv')\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    df['Total_toxic_replies'] = df['Num_toxic_direct_replies'] + df['Num_toxic_nested_replies']\n",
    "    df['Toxic_conversation'] = (df['Total_toxic_replies'] > 0).astype(int)\n",
    "    \n",
    "    print(f\"Dataset shape after preprocessing: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    print(f\"Toxic conversation distribution:\")\n",
    "    print(df['Toxic_conversation'].value_counts())\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = load_and_preprocess_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59880201",
   "metadata": {},
   "source": [
    "### 2. Model Training and Cross-Validation\n",
    "\n",
    "We train three models using 5-fold cross-validation:\n",
    "- Logistic Regression\n",
    "- Support Vector Machine\n",
    "- Random Forest\n",
    "\n",
    "We then evaluate performance using F1-score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ba1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Splitting data (80% training, 20% testing)...\n",
      "\n",
      "Logistic Regression:\n",
      "Average Accuracy: 0.7786\n",
      "Average F1 Score: 0.3038\n",
      "\n",
      "Support Vector Machine:\n"
     ]
    }
   ],
   "source": [
    "def part_a_model_selection(df):\n",
    "    print(\"\\n2. Splitting data (80% training, 20% testing)...\")\n",
    "    features_a = ['Length', 'Num_users', 'TOXICITY_x', 'Num_author_replies', 'Verified', 'Age']\n",
    "    X = df[features_a]\n",
    "    y = df['Toxic_conversation']\n",
    "    X['Verified'] = X['Verified'].astype(int)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "        'Support Vector Machine': SVC(random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        acc = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        f1 = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')\n",
    "        print(f\"Average Accuracy: {acc.mean():.4f}\")\n",
    "        print(f\"Average F1 Score: {f1.mean():.4f}\")\n",
    "        results[name] = {'model': model, 'avg_accuracy': acc.mean(), 'avg_f1': f1.mean()}\n",
    "    \n",
    "    best_model_name = max(results.keys(), key=lambda x: results[x]['avg_f1'])\n",
    "    best_model = results[best_model_name]['model']\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\nBest Model: {best_model_name}\")\n",
    "    print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Test F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return results, best_model_name\n",
    "\n",
    "results_a, best_model_name = part_a_model_selection(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea70d917",
   "metadata": {},
   "source": [
    "## Part B: Regularization Techniques\n",
    "\n",
    "We explore:\n",
    "- Unregularized Logistic Regression\n",
    "- L1 (Lasso)\n",
    "- L2 (Ridge)\n",
    "- Elastic Net\n",
    "\n",
    "We'll use a wider set of features and compare performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce46622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unregularized - Accuracy: 0.7710, F1 Score: 0.2481\n",
      "\n",
      "L1 - Accuracy: 0.7788, F1 Score: 0.3074\n",
      "\n",
      "L2 - Accuracy: 0.7710, F1 Score: 0.2481\n",
      "\n",
      "ElasticNet - Accuracy: 0.7517, F1 Score: 0.0604\n"
     ]
    }
   ],
   "source": [
    "def part_b_regularization(df):\n",
    "    features_b = ['Length', 'Num_users', 'TOXICITY_x', 'Num_author_replies', \n",
    "                  'Verified', 'Age', 'Followers', 'Friends', 'Num_tweets', \n",
    "                  'Location', 'Listed_count']\n",
    "    \n",
    "    X = df[features_b]\n",
    "    y = df['Toxic_conversation']\n",
    "    X['Verified'] = X['Verified'].astype(int)\n",
    "    X['Location'] = X['Location'].astype('category').cat.codes\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    models = {\n",
    "        'Unregularized': LogisticRegression(max_iter=1000, random_state=42),\n",
    "        'L1': LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000, random_state=42),\n",
    "        'L2': LogisticRegression(penalty='l2', max_iter=1000, random_state=42),\n",
    "        'ElasticNet': LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, \n",
    "                                         max_iter=1000, random_state=42)\n",
    "    }\n",
    "\n",
    "    scores = {}\n",
    "    for name, model in models.items():\n",
    "        acc = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        f1 = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')\n",
    "        print(f\"\\n{name} - Accuracy: {acc.mean():.4f}, F1 Score: {f1.mean():.4f}\")\n",
    "        scores[name] = (acc.mean(), f1.mean())\n",
    "\n",
    "    return scores\n",
    "\n",
    "results_b = part_b_regularization(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fbba5c",
   "metadata": {},
   "source": [
    "## Discussion: Regularization Techniques\n",
    "\n",
    "- **L1 (Lasso)**: Shrinks some coefficients to zero, helps in feature selection.\n",
    "- **L2 (Ridge)**: Shrinks all coefficients but retains them, helps reduce overfitting.\n",
    "- **Elastic Net**: Combination of L1 and L2, good for correlated features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c34a8ab",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- **Best Model in Part A**: Selected based on F1 Score.\n",
    "- **Best Regularization**: Determined by cross-validated F1 comparison.\n",
    "\n",
    "These results guide us on balancing accuracy with model simplicity and generalization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
